import pandas as pd
import pyodbc

# === ç›¸å¯¹è·¯å¾„è¯»å– CSV æ–‡ä»¶ ===
csv_path = 'afge/JobHistory20250618.csv'  # â† ç›¸å¯¹è·¯å¾„
df = pd.read_csv(csv_path, sep='|', dtype=str)

# === åˆ é™¤ç©ºåˆ—ï¼ˆé˜²æ­¢æœ€åå¤šå‡ºä¸€ä¸ª NaN åˆ—ï¼‰===
df = df.dropna(axis=1, how='all')

# === ç±»å‹è½¬æ¢ï¼ˆæ—¶é—´ + æ•°å€¼å­—æ®µï¼‰===
for time_col in ['StartTime', 'EndTime']:
    if time_col in df.columns:
        df[time_col] = pd.to_datetime(df[time_col], errors='coerce')

float_fields = [
    'MediaThickness', 'MediaWidth', 'MediaLength', 'MediaSize',
    'ImageWith', 'ImageLength', 'RequestedCopyCount', 'GoodCopyCount', 'WasteCopyCount',
    'HeadGap', 'UVLeading', 'UVTrailing', 'MaskingValue', 'TransportAdjust',
    'ActualPrintTime', 'PercentagePrinted',
    'TotalInkGoodConsumption_Black', 'TotalWasteInkConsumption_Black', 'Density_Black',
    'TotalInkGoodConsumption_Cyan', 'TotalWasteInkConsumption_Cyan', 'Density_Cyan',
    'TotalInkGoodConsumption_Magenta', 'TotalWasteInkConsumption_Magenta', 'Density_Magenta',
    'TotalInkGoodConsumption_Yellow', 'TotalWasteInkConsumption_Yellow', 'Density_Yellow',
    'TotalInkGoodConsumption_LightCyan', 'TotalWasteInkConsumption_LightCyan', 'Density_LightCyan',
    'TotalInkGoodConsumption_LightBlack', 'TotalWasteInkConsumption_LightBlack', 'Density_LightBlack',
    'TotalInkGoodConsumption_White', 'TotalWasteInkConsumption_White', 'Density_White',
    'TotalInkGoodConsumption_Varnish', 'TotalWasteInkConsumption_Varnish', 'Density_Varnish'
]

for col in float_fields:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')

# === SQL Server æ•°æ®åº“è¿æ¥é…ç½® ===
server = '172.16.1.9'
database = 'yx_test'
username = 'sa'
password = 'Ks123456'

conn_str = f'DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}'
conn = pyodbc.connect(conn_str)
cursor = conn.cursor()

table_name = 'afgePrintLog_yx'
error_rows = []
success_count = 0

print(f"ğŸ“¦ å¼€å§‹å¯¼å…¥ï¼Œå…± {len(df)} è¡Œæ•°æ®...")

for index, row in df.iterrows():
    row_number = index + 1
    columns = ', '.join(f'[{col}]' for col in row.index)
    placeholders = ', '.join('?' for _ in row)
    values = [None if pd.isna(v) else v for v in row.values]

    sql = f"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})"
    try:
        cursor.execute(sql, values)
        success_count += 1
        print(f"âœ… ç¬¬ {row_number} è¡Œå†™å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ç¬¬ {row_number} è¡Œå†™å…¥å¤±è´¥: {e}")
        error_row = row.to_dict()
        error_row['ErrorMessage'] = str(e)
        error_rows.append(error_row)

conn.commit()
cursor.close()
conn.close()

# === å†™å…¥å¤±è´¥è®°å½•åˆ° Excel ===
if error_rows:
    df_error = pd.DataFrame(error_rows)
    df_error.to_excel('afge/æ‰“å°æ—¥å¿—_æ’å…¥å¤±è´¥è®°å½•.xlsx', index=False)
    print(f"âš ï¸ æˆåŠŸ {success_count} è¡Œï¼Œå¤±è´¥ {len(error_rows)} è¡Œï¼Œå¤±è´¥è®°å½•å·²ä¿å­˜åˆ° 'afge/æ‰“å°æ—¥å¿—_æ’å…¥å¤±è´¥è®°å½•.xlsx'")
else:
    print(f"ğŸ‰ æ‰€æœ‰æ•°æ®å¯¼å…¥æˆåŠŸï¼Œå…± {success_count} è¡Œ")
